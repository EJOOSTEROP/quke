module_name_llm: langchain_huggingface
class_name_llm: HuggingFaceEndpoint
name: tiiuae/falcon-7b-instruct

# rate_limiter is optional. If it exists it needs to refer to a limiter defined in config.yaml.
rate_limiter: none

llm_args:
  repo_id: ${llm.name}
  temperature: 0.1
  max_new_tokens: 512  
  model_kwargs: 
    max_length: 2000
    num_return_sequences: 3
